{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.init as init\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.optim.lr_scheduler import ExponentialLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConnection(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, f_m, f_s=None):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_m = f_m\n",
    "        self.f_s = f_s\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        \"\"\"\n",
    "        if self.f_s is not None:\n",
    "            return self.relu(self.f_s(X) + self.f_m(X))\n",
    "        else:\n",
    "            return self.relu(X + self.f_m(X))\n",
    "        \n",
    "class AverageMeter(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class Accuracy(object):\n",
    "    \n",
    "    def __init__(self, reduction=\"sum\"):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        \"\"\"\n",
    "        if reduction not in [\"mean\", \"sum\"]:\n",
    "            raise AttributeError('The reduction can be either sum or mean')\n",
    "            \n",
    "        self.reduction = reduction\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, x ,y):\n",
    "        if self.reduction == \"sum\":\n",
    "            return (x.argmax(1) == y).float().sum().item()\n",
    "        else:\n",
    "            return (x.argmax(1) == y).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "_ = g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"device\": torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "    \"checkpoint_path\":\"./chkp/model_checkpoint_64.pt\"\n",
    "}\n",
    "\n",
    "cfg_CIFAR = {\n",
    "    \"root\":\"./data\",\n",
    "    \"download\":False\n",
    "}\n",
    "\n",
    "cfg_dataloader_train = {\n",
    "    \"batch_size\":64,\n",
    "    \"shuffle\":True,\n",
    "    \"num_workers\":2,\n",
    "    \"pin_memory\":True,\n",
    "    \"worker_init_fn\":seed_worker,\n",
    "    \"generator\":g,\n",
    "}\n",
    "\n",
    "cfg_dataloader_test = {\n",
    "    \"batch_size\":1024,\n",
    "    \"shuffle\":False,\n",
    "    \"num_workers\":2,\n",
    "    \"pin_memory\":True,\n",
    "}\n",
    "\n",
    "cfg_train = {\n",
    "    \"n_epoches\":200,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CIFAR10(transform=transforms.Compose([\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.RandomCrop(32, 4),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])]\n",
    "                    ), **cfg_CIFAR, train=True)\n",
    "trainloader = DataLoader(trainset, **cfg_dataloader_train)\n",
    "\n",
    "testset = CIFAR10(transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])]\n",
    "                    ), **cfg_CIFAR, train=False)\n",
    "testloader = DataLoader(testset, **cfg_dataloader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet20 = nn.Sequential(\n",
    "    ### Initial Layer\n",
    "    nn.Conv2d(3, 16, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    ### 16x16 Block of 3 Connections\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "    ),\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "    ),\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    ### Downsampling\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        ),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        ),\n",
    "    ),\n",
    "    \n",
    "    ### 32x32 Block of 2 Connections\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "    ),\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    ### Downsampling\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        ),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        ),\n",
    "    ),\n",
    "    \n",
    "    ### 64x64 Block of 2 Connections\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "    ),\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    ### Flattening\n",
    "    nn.AvgPool2d(8),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    \n",
    "    ### Head Layer\n",
    "    nn.Linear(64, 10)\n",
    ").to(cfg[\"device\"])\n",
    "\n",
    "optimResNet20 = AdamW(ResNet20.parameters(), lr=1e-2)\n",
    "schedResNet20 = ExponentialLR(optimResNet20, gamma=0.1)\n",
    "schedule = [100, 150]\n",
    "CELoss = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "Acc = Accuracy(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(cfg[\"checkpoint_path\"])\n",
    "_ = ResNet20.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CE 0.346, Acc 0.928: 100%|██████████| 10/10 [00:01<00:00,  8.89it/s]\n"
     ]
    }
   ],
   "source": [
    "ResNet20.eval()\n",
    "with torch.no_grad():\n",
    "    err_CE = 0\n",
    "    err_acc = 0\n",
    "    n_elem = 0\n",
    "\n",
    "    for X_batch, y_batch in (pbar := tqdm(testloader)):\n",
    "        X_batch = X_batch.to(cfg[\"device\"])\n",
    "        y_batch = y_batch.to(cfg[\"device\"])\n",
    "\n",
    "        logits = ResNet20(X_batch)\n",
    "        output = CELoss(logits, y_batch)\n",
    "        accuracy = Acc(logits, y_batch)\n",
    "\n",
    "        batch_shape = X_batch.shape[0]\n",
    "        n_elem += batch_shape\n",
    "        err_CE += output.item()\n",
    "        err_acc += accuracy\n",
    "        pbar.set_description(\"CE {:.3f}, Acc {:.3f}\".format(err_CE/n_elem, err_acc/n_elem))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Builtin PTQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.quantization' has no attribute 'get_default_config'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-af7c44f15b95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# set quantization config for server (x86)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdeploymentmyModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fbgemm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# insert observers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mResNet20PTQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResNet20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.quantization' has no attribute 'get_default_config'"
     ]
    }
   ],
   "source": [
    "# set quantization config for server (x86)\n",
    "deploymentmyModel.qconfig = torch.quantization.get_default_config('fbgemm')\n",
    "\n",
    "# insert observers\n",
    "ResNet20PTQ = torch.quantization.prepare(ResNet20, inplace=False)\n",
    "# Calibrate the model and collect statistics\n",
    "\n",
    "# convert to quantized version\n",
    "ResNet20PTQ = torch.quantization.convert(ResNet20PTQ, inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
