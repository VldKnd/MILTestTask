{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utilities\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "### Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "### Quantization\n",
    "from torch.quantization.qconfig import QConfig\n",
    "from torch.quantization.observer import MinMaxObserver\n",
    "\n",
    "### Custom\n",
    "from src.model import ResNet20\n",
    "from src.train import validate\n",
    "from src.utils import Accuracy, get_model_size\n",
    "from src.qmodel import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cfg/new_64_200.json\") as configurations:\n",
    "    cfg, cfg_CIFAR, cfg_dataloader_train, cfg_dataloader_test, cfg_train = json.load(configurations).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CIFAR10(transform=transforms.Compose([\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.RandomCrop(32, 4),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])]\n",
    "                    ), **cfg_CIFAR, train=True)\n",
    "trainloader = DataLoader(trainset, **cfg_dataloader_train)\n",
    "\n",
    "testset = CIFAR10(transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])]\n",
    "                    ), **cfg_CIFAR, train=False)\n",
    "testloader = DataLoader(testset, **cfg_dataloader_test)\n",
    "\n",
    "n_q, idxes = 10, torch.randperm(len(trainset))\n",
    "qloader = DataLoader([trainset[idxes[i]] for i in range(n_q)], **cfg_dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "from_checkpoint = os.path.exists(cfg[\"checkpoint_path\"])\n",
    "cfg[\"device\"] = torch.device(\"cuda\") if is_cuda \\\n",
    "            else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet = ResNet20().to(cfg[\"device\"])\n",
    "CELoss = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "Acc = Accuracy(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimResNet = AdamW(ResNet.parameters(), lr=1e-2)\n",
    "schedResNet = MultiStepLR(optimResNet, last_epoch=-1,\n",
    "                            milestones=[100, 150], gamma=0.1)\n",
    "\n",
    "if from_checkpoint:\n",
    "    checkpoint = torch.load(cfg[\"checkpoint_path\"], map_location=cfg[\"device\"])\n",
    "    last_epoch = checkpoint[\"epoch\"] + 1\n",
    "    best_acc = checkpoint[\"best_acc\"]\n",
    "    ResNet.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimResNet.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    schedResNet.load_state_dict(checkpoint[\"scheduler\"])\n",
    "    \n",
    "CELoss = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "Acc = Accuracy(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 0.087, Accuracy: 0.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Load Checkpoint\")\n",
    "ce, acc = validate(qloader, ResNet, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "print(\"Cross Entropy: {:.3f}, Accuracy: {:.3f}\".format(ce.avg, acc.avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Statistics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 22.003, Accuracy: 0.097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qconfig_int2 = QConfig(\n",
    "    activation=MinMaxObserver.with_args(\n",
    "        dtype=torch.quint8,\n",
    "        quant_min=0,\n",
    "        quant_max=3\n",
    "    ),\n",
    "    weight=MinMaxObserver.with_args(\n",
    "        dtype=torch.qint8,\n",
    "        quant_min=-2,\n",
    "        quant_max=1\n",
    "    )\n",
    ")\n",
    "    \n",
    "ResNetPTQint2 = torch.quantization.QuantWrapper(\n",
    "    copy.deepcopy(ResNet)\n",
    ")\n",
    "\n",
    "ResNetPTQint2.qconfig = qconfig_int2\n",
    "torch.quantization.prepare(ResNetPTQint2, inplace=True)\n",
    "\n",
    "print(\"Compute Statistics\")\n",
    "ce, acc = validate(qloader, ResNetPTQint2, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "_ = torch.quantization.convert(ResNetPTQint2, inplace=True)\n",
    "\n",
    "print(\"Evaluate\")\n",
    "ce, acc = validate(testloader, ResNetPTQint2, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "print(\"Cross Entropy: {:.3f}, Accuracy: {:.3f}\".format(ce.avg, acc.avg))\n",
    "\n",
    "torch.save(ResNetPTQint2.state_dict(), cfg[\"checkpoint_path\"]+\"_int2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Statistics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 8.808, Accuracy: 0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qconfig_int4 = torch.quantization.qconfig.QConfig(\n",
    "    activation=MinMaxObserver.with_args(\n",
    "        dtype=torch.quint8,\n",
    "        quant_min=0,\n",
    "        quant_max=15\n",
    "    ),\n",
    "    weight=MinMaxObserver.with_args(\n",
    "        dtype=torch.qint8,\n",
    "        quant_min =-8,\n",
    "        quant_max =7,\n",
    "    )\n",
    ")\n",
    "\n",
    "ResNetPTQint4 = torch.quantization.QuantWrapper(\n",
    "    copy.deepcopy(ResNet)\n",
    ")\n",
    "\n",
    "ResNetPTQint4.qconfig = qconfig_int4\n",
    "torch.quantization.prepare(ResNetPTQint4, inplace=True)\n",
    "\n",
    "print(\"Compute Statistics\")\n",
    "ce, acc = validate(qloader, ResNetPTQint4, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "_ = torch.quantization.convert(ResNetPTQint4, inplace=True)\n",
    "print(\"Evaluate\")\n",
    "ce, acc = validate(testloader, ResNetPTQint4, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "print(\"Cross Entropy: {:.3f}, Accuracy: {:.3f}\".format(ce.avg, acc.avg))\n",
    "\n",
    "torch.save(ResNetPTQint4.state_dict(), cfg[\"checkpoint_path\"]+\"_int4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Statistics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:29<00:00,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 0.416, Accuracy: 0.880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qconfig_int8 = torch.quantization.qconfig.QConfig(\n",
    "    activation=MinMaxObserver.with_args(\n",
    "        dtype=torch.quint8\n",
    "    ),\n",
    "    weight=MinMaxObserver.with_args(\n",
    "        dtype=torch.qint8\n",
    "    )\n",
    ")\n",
    "\n",
    "ResNetPTQint8 = torch.quantization.QuantWrapper(\n",
    "    copy.deepcopy(ResNet)\n",
    ")\n",
    "\n",
    "ResNetPTQint8.qconfig = qconfig_int8\n",
    "torch.quantization.prepare(ResNetPTQint8, inplace=True)\n",
    "\n",
    "print(\"Compute Statistics\")\n",
    "ResNetPTQint8.eval()\n",
    "ce, acc = validate(qloader, ResNetPTQint8, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "_ = torch.quantization.convert(ResNetPTQint8, inplace=True)\n",
    "ResNetPTQint8.eval()\n",
    "print(\"Evaluate\")\n",
    "ce, acc = validate(testloader, ResNetPTQint8, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "print(\"Cross Entropy: {:.3f}, Accuracy: {:.3f}\".format(ce.avg, acc.avg))\n",
    "\n",
    "torch.save(ResNetPTQint8.state_dict(), cfg[\"checkpoint_path\"]+\"_int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model Size: 0.370 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:17<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 0.779, Accuracy: 0.830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "QuantizedNN = quantize_merge_model(ResNet)\n",
    "ce, acc = validate(qloader, QuantizedNN, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "QuantizedNN.apply(compile_module)\n",
    "print(\"Quantized Model Size: {:.3f} MB\".format(get_model_size(QuantizedNN)))\n",
    "ce, acc = validate(testloader, QuantizedNN, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "print(\"Cross Entropy: {:.3f}, Accuracy: {:.3f}\".format(ce.avg, acc.avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare size and speed execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal Model Size: 1.478 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normal Model Time 43.272s ± 5.276s: 100%|██████████| 5/5 [03:36<00:00, 43.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model Size: 0.015 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qunatized Model Time 22.778s ± 0.090s: 100%|██████████| 5/5 [01:53<00:00, 22.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hands-on Quantized Model Size: 0.370 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qunatized Model Time 16.079s ± 0.023s: 100%|██████████| 5/5 [01:20<00:00, 16.08s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Normal Model Size: {:.3f} MB\".format(get_model_size(ResNet)))\n",
    "time_norm = []\n",
    "for i in (pbar := tqdm(range(5))):\n",
    "    start_time = time()\n",
    "    validate(testloader, ResNet, CELoss, Acc, torch.device(\"cpu\"))\n",
    "    time_norm.append(time() - start_time)\n",
    "    pbar.set_description('Normal Model Time {:.3f}s \\u00B1 {:.3f}s'.format(np.mean(time_norm), np.std(time_norm)))\n",
    "\n",
    "print(\"Quantized Model Size: {:.3f} MB\".format(get_model_size(ResNetPTQint8)))\n",
    "time_quant = []\n",
    "for i in (pbar := tqdm(range(5))):\n",
    "    start_time = time()\n",
    "    validate(testloader, ResNetPTQint8, CELoss, Acc, torch.device(\"cpu\"))\n",
    "    time_quant.append(time() - start_time)\n",
    "    pbar.set_description('Qunatized Model Time {:.3f}s \\u00B1 {:.3f}s'.format(np.mean(time_quant), np.std(time_quant)))\n",
    "\n",
    "print(\"Hands-on Quantized Model Size: {:.3f} MB\".format(get_model_size(QuantizedNN)))\n",
    "time_quant = []\n",
    "for i in (pbar := tqdm(range(5))):\n",
    "    start_time = time()\n",
    "    validate(testloader, QuantizedNN, CELoss, Acc, torch.device(\"cpu\"))\n",
    "    time_quant.append(time() - start_time)\n",
    "    pbar.set_description('Qunatized Model Time {:.3f}s \\u00B1 {:.3f}s'.format(np.mean(time_quant), np.std(time_quant)))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
