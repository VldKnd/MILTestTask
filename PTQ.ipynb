{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Utilities\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "### Torch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "### Quantization\n",
    "from torch.quantization.qconfig import QConfig\n",
    "from torch.quantization.observer import MinMaxObserver\n",
    "\n",
    "### Custom\n",
    "from src.model import ResNet20\n",
    "from src.train import validate\n",
    "from src.utils import Accuracy, get_model_size\n",
    "from src.qmodel import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"cfg/new_64_200.json\") as configurations:\n",
    "    cfg, cfg_CIFAR, cfg_dataloader_train, cfg_dataloader_test, cfg_train = json.load(configurations).values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CIFAR10(transform=transforms.Compose([\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.RandomCrop(32, 4),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])]\n",
    "                    ), **cfg_CIFAR, train=True)\n",
    "trainloader = DataLoader(trainset, **cfg_dataloader_train)\n",
    "\n",
    "testset = CIFAR10(transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])]\n",
    "                    ), **cfg_CIFAR, train=False)\n",
    "testloader = DataLoader(testset, **cfg_dataloader_test)\n",
    "\n",
    "n_q, idxes = 10, torch.randperm(len(trainset))\n",
    "qloader = DataLoader([trainset[idxes[i]] for i in range(n_q)], **cfg_dataloader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "from_checkpoint = os.path.exists(cfg[\"checkpoint_path\"])\n",
    "cfg[\"device\"] = torch.device(\"cuda\") if is_cuda \\\n",
    "            else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet = ResNet20().to(cfg[\"device\"])\n",
    "CELoss = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "Acc = Accuracy(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimResNet = AdamW(ResNet.parameters(), lr=1e-2)\n",
    "schedResNet = MultiStepLR(optimResNet, last_epoch=-1,\n",
    "                            milestones=[100, 150], gamma=0.1)\n",
    "\n",
    "if from_checkpoint:\n",
    "    checkpoint = torch.load(cfg[\"checkpoint_path\"], map_location=cfg[\"device\"])\n",
    "    last_epoch = checkpoint[\"epoch\"] + 1\n",
    "    best_acc = checkpoint[\"best_acc\"]\n",
    "    ResNet.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimResNet.load_state_dict(checkpoint[\"optimizer\"])\n",
    "    schedResNet.load_state_dict(checkpoint[\"scheduler\"])\n",
    "    \n",
    "CELoss = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "Acc = Accuracy(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 0.087, Accuracy: 0.900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Load Checkpoint\")\n",
    "ce, acc = validate(qloader, ResNet, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "print(\"Cross Entropy: {:.3f}, Accuracy: {:.3f}\".format(ce.avg, acc.avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Statistics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:23<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 22.003, Accuracy: 0.097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qconfig_int2 = QConfig(\n",
    "    activation=MinMaxObserver.with_args(\n",
    "        dtype=torch.quint8,\n",
    "        quant_min=0,\n",
    "        quant_max=3\n",
    "    ),\n",
    "    weight=MinMaxObserver.with_args(\n",
    "        dtype=torch.qint8,\n",
    "        quant_min=-2,\n",
    "        quant_max=1\n",
    "    )\n",
    ")\n",
    "    \n",
    "ResNetPTQint2 = torch.quantization.QuantWrapper(\n",
    "    copy.deepcopy(ResNet)\n",
    ")\n",
    "\n",
    "ResNetPTQint2.qconfig = qconfig_int2\n",
    "torch.quantization.prepare(ResNetPTQint2, inplace=True)\n",
    "\n",
    "print(\"Compute Statistics\")\n",
    "ce, acc = validate(qloader, ResNetPTQint2, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "_ = torch.quantization.convert(ResNetPTQint2, inplace=True)\n",
    "\n",
    "print(\"Evaluate\")\n",
    "ce, acc = validate(testloader, ResNetPTQint2, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "print(\"Cross Entropy: {:.3f}, Accuracy: {:.3f}\".format(ce.avg, acc.avg))\n",
    "\n",
    "torch.save(ResNetPTQint2.state_dict(), cfg[\"checkpoint_path\"]+\"_int2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Statistics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:24<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 8.808, Accuracy: 0.266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qconfig_int4 = torch.quantization.qconfig.QConfig(\n",
    "    activation=MinMaxObserver.with_args(\n",
    "        dtype=torch.quint8,\n",
    "        quant_min=0,\n",
    "        quant_max=15\n",
    "    ),\n",
    "    weight=MinMaxObserver.with_args(\n",
    "        dtype=torch.qint8,\n",
    "        quant_min =-8,\n",
    "        quant_max =7,\n",
    "    )\n",
    ")\n",
    "\n",
    "ResNetPTQint4 = torch.quantization.QuantWrapper(\n",
    "    copy.deepcopy(ResNet)\n",
    ")\n",
    "\n",
    "ResNetPTQint4.qconfig = qconfig_int4\n",
    "torch.quantization.prepare(ResNetPTQint4, inplace=True)\n",
    "\n",
    "print(\"Compute Statistics\")\n",
    "ce, acc = validate(qloader, ResNetPTQint4, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "_ = torch.quantization.convert(ResNetPTQint4, inplace=True)\n",
    "print(\"Evaluate\")\n",
    "ce, acc = validate(testloader, ResNetPTQint4, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "print(\"Cross Entropy: {:.3f}, Accuracy: {:.3f}\".format(ce.avg, acc.avg))\n",
    "\n",
    "torch.save(ResNetPTQint4.state_dict(), cfg[\"checkpoint_path\"]+\"_int4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Statistics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:29<00:00,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 0.416, Accuracy: 0.880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qconfig_int8 = torch.quantization.qconfig.QConfig(\n",
    "    activation=MinMaxObserver.with_args(\n",
    "        dtype=torch.quint8\n",
    "    ),\n",
    "    weight=MinMaxObserver.with_args(\n",
    "        dtype=torch.qint8\n",
    "    )\n",
    ")\n",
    "\n",
    "ResNetPTQint8 = torch.quantization.QuantWrapper(\n",
    "    copy.deepcopy(ResNet)\n",
    ")\n",
    "\n",
    "ResNetPTQint8.qconfig = qconfig_int8\n",
    "torch.quantization.prepare(ResNetPTQint8, inplace=True)\n",
    "\n",
    "print(\"Compute Statistics\")\n",
    "ResNetPTQint8.eval()\n",
    "ce, acc = validate(qloader, ResNetPTQint8, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "_ = torch.quantization.convert(ResNetPTQint8, inplace=True)\n",
    "ResNetPTQint8.eval()\n",
    "print(\"Evaluate\")\n",
    "ce, acc = validate(testloader, ResNetPTQint8, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "print(\"Cross Entropy: {:.3f}, Accuracy: {:.3f}\".format(ce.avg, acc.avg))\n",
    "\n",
    "torch.save(ResNetPTQint8.state_dict(), cfg[\"checkpoint_path\"]+\"_int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Statistics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 0.290, Accuracy: 0.912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "qconfig_int8 = torch.quantization.qconfig.QConfig(\n",
    "    activation=MinMaxObserver.with_args(\n",
    "        dtype=torch.quint8\n",
    "    ),\n",
    "    weight=MinMaxObserver.with_args(\n",
    "        dtype=torch.qint8\n",
    "    )\n",
    ")\n",
    "\n",
    "ResNetPTQFuseint8 = copy.deepcopy(ResNet)\n",
    "\n",
    "modules_to_fuse = [\n",
    "['0','1', '2'],\n",
    "\n",
    "['3.f.0', '3.f.1','3.f.2'], ['3.f.3', '3.f.4',],\n",
    "['4.f.0', '4.f.1','4.f.2'], ['4.f.3', '4.f.4',],\n",
    "['5.f.0', '5.f.1','5.f.2'], ['5.f.3', '5.f.4',],\n",
    "\n",
    "['6.f.0', '6.f.1','6.f.2'], ['6.f.3', '6.f.4',],\n",
    "['6.c.0','6.c.1'],\n",
    "\n",
    "['7.f.0', '7.f.1','7.f.2'], ['7.f.3', '7.f.4',],\n",
    "['8.f.0', '8.f.1','8.f.2'], ['8.f.3', '8.f.4',],\n",
    "['9.f.0', '9.f.1','9.f.2'], ['9.f.3', '9.f.4',],\n",
    "\n",
    "['10.f.0', '10.f.1','10.f.2'], ['10.f.3', '10.f.4',],\n",
    "['10.c.0','10.c.1'],\n",
    "\n",
    "['11.f.0', '11.f.1','11.f.2'], ['11.f.3', '11.f.4',],\n",
    "['12.f.0', '12.f.1','12.f.2'], ['12.f.3', '12.f.4',],\n",
    "['13.f.0', '13.f.1','13.f.2'], ['13.f.3', '13.f.4',]\n",
    "]\n",
    "\n",
    "torch.quantization.fuse_modules(ResNetPTQFuseint8, modules_to_fuse, inplace=True)\n",
    "ResNetPTQFuseint8 = torch.quantization.QuantWrapper(\n",
    "    ResNetPTQFuseint8\n",
    ")\n",
    "\n",
    "ResNetPTQFuseint8.qconfig = qconfig_int8\n",
    "torch.quantization.prepare(ResNetPTQFuseint8, inplace=True)\n",
    "\n",
    "print(\"Compute Statistics\")\n",
    "ResNetPTQFuseint8.eval()\n",
    "ce, acc = validate(qloader, ResNetPTQFuseint8, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "_ = torch.quantization.convert(ResNetPTQFuseint8, inplace=True)\n",
    "ResNetPTQFuseint8.eval()\n",
    "print(\"Evaluate\")\n",
    "ce, acc = validate(testloader, ResNetPTQFuseint8, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "print(\"Cross Entropy: {:.3f}, Accuracy: {:.3f}\".format(ce.avg, acc.avg))\n",
    "\n",
    "torch.save(ResNetPTQFuseint8.state_dict(), cfg[\"checkpoint_path\"]+\"_int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized Model Size: 0.370 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:16<00:00,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Entropy: 0.779, Accuracy: 0.830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "QuantizedNN = quantize_merge_model(ResNet)\n",
    "ce, acc = validate(qloader, QuantizedNN, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "QuantizedNN.apply(compile_module)\n",
    "print(\"Quantized Model Size: {:.3f} MB\".format(get_model_size(QuantizedNN)))\n",
    "ce, acc = validate(testloader, QuantizedNN, CELoss, Acc, cfg[\"device\"], verbose=True)\n",
    "print(\"Cross Entropy: {:.3f}, Accuracy: {:.3f}\".format(ce.avg, acc.avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare size and speed execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–\n",
      "Normal Model Size: 1.478 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Normal Model Time 39.631s ± 0.754s: 100%|██████████| 5/5 [03:18<00:00, 39.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–\n",
      "Quantized Model Size: 0.015 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qunatized Model Time 22.761s ± 0.050s: 100%|██████████| 5/5 [01:53<00:00, 22.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–\n",
      "Fused Quantized Model Size: 0.000 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qunatized Model Time 15.632s ± 0.075s: 100%|██████████| 5/5 [01:18<00:00, 15.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–\n",
      "Hands-on Quantized Model Size: 0.370 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Qunatized Model Time 16.216s ± 0.231s: 100%|██████████| 5/5 [01:21<00:00, 16.22s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"-|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–\")\n",
    "print(\"Normal Model Size: {:.3f} MB\".format(get_model_size(ResNet)))\n",
    "time_norm = []\n",
    "for i in (pbar := tqdm(range(5))):\n",
    "    start_time = time()\n",
    "    validate(testloader, ResNet, CELoss, Acc, torch.device(\"cpu\"))\n",
    "    time_norm.append(time() - start_time)\n",
    "    pbar.set_description('Normal Model Time {:.3f}s \\u00B1 {:.3f}s'.format(np.mean(time_norm), np.std(time_norm)))\n",
    "    \n",
    "print(\"-|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–\")\n",
    "print(\"Quantized Model Size: {:.3f} MB\".format(get_model_size(ResNetPTQint8)))\n",
    "time_quant = []\n",
    "for i in (pbar := tqdm(range(5))):\n",
    "    start_time = time()\n",
    "    validate(testloader, ResNetPTQint8, CELoss, Acc, torch.device(\"cpu\"))\n",
    "    time_quant.append(time() - start_time)\n",
    "    pbar.set_description('Qunatized Model Time {:.3f}s \\u00B1 {:.3f}s'.format(np.mean(time_quant), np.std(time_quant)))\n",
    "\n",
    "print(\"-|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–\")\n",
    "print(\"Fused Quantized Model Size: {:.3f} MB\".format(get_model_size(ResNetPTQFuseint8)))\n",
    "time_quant = []\n",
    "for i in (pbar := tqdm(range(5))):\n",
    "    start_time = time()\n",
    "    validate(testloader, ResNetPTQFuseint8, CELoss, Acc, torch.device(\"cpu\"))\n",
    "    time_quant.append(time() - start_time)\n",
    "    pbar.set_description('Fused Qunatized Model Time {:.3f}s \\u00B1 {:.3f}s'.format(np.mean(time_quant), np.std(time_quant)))\n",
    "\n",
    "print(\"-|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–|-|-|-|–\")\n",
    "print(\"Hands-on Quantized Model Size: {:.3f} MB\".format(get_model_size(QuantizedNN)))\n",
    "time_quant = []\n",
    "for i in (pbar := tqdm(range(5))):\n",
    "    start_time = time()\n",
    "    validate(testloader, QuantizedNN, CELoss, Acc, torch.device(\"cpu\"))\n",
    "    time_quant.append(time() - start_time)\n",
    "    pbar.set_description('Qunatized Model Time {:.3f}s \\u00B1 {:.3f}s'.format(np.mean(time_quant), np.std(time_quant)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.quantize_per_tensor(torch.randn(10), 1., 0, torch.qint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'named_children'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/qs/bg42mlln1f73lqvrb25zssr40000gp/T/ipykernel_77074/2808386032.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquantization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/ao/quantization/quantize.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(module, mapping, inplace, remove_qconfig, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    503\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m     _convert(\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         convert_custom_config_dict=convert_custom_config_dict)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/ao/quantization/quantize.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(module, mapping, inplace, convert_custom_config_dict)\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0mreassign\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m         \u001b[0;31m# both fused modules and observed custom modules are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m         \u001b[0;31m# swapped as one unit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'named_children'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.element_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
