{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.init as init\n",
    "from torch.optim import AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torch.optim.lr_scheduler import ExponentialLR, MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipConnection(torch.nn.Module):\n",
    "    def __init__(self, f_m, f_s=None):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.f_m = f_m\n",
    "        self.f_s = f_s\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        \"\"\"\n",
    "        if self.f_s is not None:\n",
    "            return self.relu(self.f_s(X) + self.f_m(X))\n",
    "        else:\n",
    "            return self.relu(X + self.f_m(X))\n",
    "        \n",
    "class AverageMeter(object):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class Accuracy(object):\n",
    "        \"\"\"\n",
    "        Description\n",
    "        \"\"\"\n",
    "    def __init__(self, reduction=\"sum\"):\n",
    "        if reduction not in [\"mean\", \"sum\"]:\n",
    "            raise AttributeError('The reduction can be either sum or mean')\n",
    "            \n",
    "        self.reduction = reduction\n",
    "        \n",
    "    @torch.no_grad()\n",
    "    def __call__(self, x ,y):\n",
    "        if self.reduction == \"sum\":\n",
    "            return (x.argmax(1) == y).float().sum().item()\n",
    "        else:\n",
    "            return (x.argmax(1) == y).float().mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions from PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self, name, fmt=':f'):\n",
    "        self.name = name\n",
    "        self.fmt = fmt\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "    def __str__(self):\n",
    "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
    "        return fmtstr.format(**self.__dict__)\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "        res = []\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "            res.append(correct_k.mul_(100.0 / batch_size))\n",
    "        return res\n",
    "\n",
    "\n",
    "def evaluate(model, criterion, data_loader, neval_batches):\n",
    "    model.eval()\n",
    "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
    "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for image, target in data_loader:\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "            cnt += 1\n",
    "            acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
    "            print('.', end = '')\n",
    "            top1.update(acc1[0], image.size(0))\n",
    "            top5.update(acc5[0], image.size(0))\n",
    "            if cnt >= neval_batches:\n",
    "                 return top1, top5\n",
    "\n",
    "    return top1, top5\n",
    "\n",
    "def load_model(model_file):\n",
    "    model = MobileNetV2()\n",
    "    state_dict = torch.load(model_file)\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to('cpu')\n",
    "    return model\n",
    "\n",
    "def print_size_of_model(model):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    print('Size (MB):', os.path.getsize(\"temp.p\")/1e6)\n",
    "    os.remove('temp.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random \n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "_ = g.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"device\": torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\"),\n",
    "    \"checkpoint_path\":\"./chkp/model_checkpoint_64_check.pt\"\n",
    "}\n",
    "\n",
    "cfg_CIFAR = {\n",
    "    \"root\":\"./data\",\n",
    "    \"download\":False\n",
    "}\n",
    "\n",
    "cfg_dataloader_train = {\n",
    "    \"batch_size\":64,\n",
    "    \"shuffle\":True,\n",
    "    \"num_workers\":2,\n",
    "    \"pin_memory\":True,\n",
    "    \"worker_init_fn\":seed_worker,\n",
    "    \"generator\":g,\n",
    "}\n",
    "\n",
    "cfg_dataloader_test = {\n",
    "    \"batch_size\":1024,\n",
    "    \"shuffle\":False,\n",
    "    \"num_workers\":2,\n",
    "    \"pin_memory\":True,\n",
    "}\n",
    "\n",
    "cfg_train = {\n",
    "    \"n_epoches\":200,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = CIFAR10(transform=transforms.Compose([\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.RandomCrop(32, 4),\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])]\n",
    "                    ), **cfg_CIFAR, train=True)\n",
    "trainloader = DataLoader(trainset, **cfg_dataloader_train)\n",
    "\n",
    "testset = CIFAR10(transform=transforms.Compose([\n",
    "                        transforms.ToTensor(),\n",
    "                        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                             std=[0.229, 0.224, 0.225])]\n",
    "                    ), **cfg_CIFAR, train=False)\n",
    "testloader = DataLoader(testset, **cfg_dataloader_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ResNet20 = nn.Sequential(\n",
    "    ### Initial Layer\n",
    "    nn.Conv2d(3, 16, 3, padding=1, bias=False),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    \n",
    "    ### 16x16 Block of 3 Connections\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "    ),\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "    ),\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(16),\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    ### Downsampling\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        ),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(16, 32, 3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        ),\n",
    "    ),\n",
    "    \n",
    "    ### 32x32 Block of 2 Connections\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "    ),\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 32, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    ### Downsampling\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        ),\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(32, 64, 3, padding=1, stride=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        ),\n",
    "    ),\n",
    "    \n",
    "    ### 64x64 Block of 2 Connections\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "    ),\n",
    "    SkipConnection(\n",
    "        nn.Sequential(\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 64, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "        )\n",
    "    ),\n",
    "    \n",
    "    ### Flattening\n",
    "    nn.AvgPool2d(8),\n",
    "    nn.Flatten(start_dim=1, end_dim=-1),\n",
    "    \n",
    "    ### Head Layer\n",
    "    nn.Linear(64, 10)\n",
    ").to(cfg[\"device\"])\n",
    "\n",
    "optimResNet20 = AdamW(ResNet20.parameters(), lr=1e-2)\n",
    "schedResNet20 = ExponentialLR(optimResNet20, gamma=0.1)\n",
    "schedule = [100, 150]\n",
    "CELoss = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "Acc = Accuracy(reduction=\"sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train: CE 0.014 Acc. 0.996| Test: CE 0.346 Acc. 0.928 | LR: 0.0001: 100%|██████████| 200/200 [54:48<00:00, 16.44s/it]\n"
     ]
    }
   ],
   "source": [
    "best_metric_acc = None\n",
    "best_metric_CE = None\n",
    "\n",
    "train_meter_CE = []\n",
    "train_meter_acc = []\n",
    "\n",
    "test_meter_CE = []\n",
    "test_meter_acc = []\n",
    "\n",
    "for e in (pbar := tqdm(range(cfg_train[\"n_epoches\"]))):\n",
    "    err_CE = 0\n",
    "    err_acc = 0\n",
    "    n_elem = 0\n",
    "    \n",
    "    ResNet20.train()\n",
    "    for X_batch, y_batch in trainloader:\n",
    "        optimResNet20.zero_grad()\n",
    "        X_batch = X_batch.to(cfg[\"device\"])\n",
    "        y_batch = y_batch.to(cfg[\"device\"])\n",
    "        \n",
    "        logits = ResNet20(X_batch)\n",
    "        output = CELoss(logits, y_batch)\n",
    "        accuracy = Acc(logits, y_batch)\n",
    "        \n",
    "        output.backward()\n",
    "        optimResNet20.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_shape = X_batch.shape[0]\n",
    "            n_elem += batch_shape\n",
    "            err_CE += output.item()\n",
    "            err_acc += accuracy\n",
    "\n",
    "    train_meter_CE.append(err_CE/n_elem)\n",
    "    train_meter_acc.append(err_acc/n_elem)\n",
    "\n",
    "    ResNet20.eval()\n",
    "    with torch.no_grad():\n",
    "        err_CE = 0\n",
    "        err_acc = 0\n",
    "        n_elem = 0\n",
    "\n",
    "        for X_batch, y_batch in testloader:\n",
    "            X_batch = X_batch.to(cfg[\"device\"])\n",
    "            y_batch = y_batch.to(cfg[\"device\"])\n",
    "\n",
    "            logits = ResNet20(X_batch)\n",
    "            output = CELoss(logits, y_batch)\n",
    "            accuracy = Acc(logits, y_batch)\n",
    "            \n",
    "            batch_shape = X_batch.shape[0]\n",
    "            n_elem += batch_shape\n",
    "            err_CE += output.item()\n",
    "            err_acc += accuracy\n",
    "\n",
    "        test_meter_CE.append(err_CE/n_elem)\n",
    "        test_meter_acc.append(err_acc/n_elem)\n",
    "\n",
    "    if best_metric_acc is None:\n",
    "        best_metric_CE = test_meter_CE[-1]\n",
    "        best_metric_acc = test_meter_acc[-1]\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': ResNet20.state_dict(),\n",
    "            'optimizer_state_dict': optimResNet20.state_dict(),\n",
    "            'CE': best_metric_CE,\n",
    "            \"Acc\":best_metric_acc,\n",
    "            }, cfg[\"checkpoint_path\"])\n",
    "        \n",
    "    elif best_metric_acc < (LOSS := test_meter_acc[-1]):\n",
    "        best_metric_CE = test_meter_CE[-1]\n",
    "        best_metric_acc = LOSS\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': ResNet20.state_dict(),\n",
    "            'optimizer_state_dict': optimResNet20.state_dict(),\n",
    "            'CE': best_metric_CE,\n",
    "            \"Acc\":best_metric_acc,\n",
    "            }, cfg[\"checkpoint_path\"])\n",
    "        \n",
    "    if (e+1) in schedule:\n",
    "        schedResNet20.step()\n",
    "        \n",
    "    pbar.set_description(\"Train: CE {:.3f} Acc. {:.3f}| Test: CE {:.3f} Acc. {:.3f} | LR: {}\".format(\n",
    "        train_meter_CE[-1], train_meter_acc[-1], best_metric_CE, best_metric_acc, schedResNet20.get_last_lr()[0]\n",
    "    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
