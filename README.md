#### Структура:
```
.
├── cfg                   
│   ├── 64_200.json     ### Файл с конфигурацией нейронной сети и DataLoader, которые я использовал для обучения ResNet
│   └── example.json    ### Пример возможного файла с конфигурацией
├── chkp                ### Сохраненные веса для моделей  
│   ├── 64_200          ### Веса для не квантированного ResNet20, точность на тест 92%
│   ├── 64_200_int2     ### Веса для квантированного ResNet20 в int2
│   ├── 64_200_int4     ### Веса для квантированного ResNet20 в int4
│   └── 64_200_int8     ### Веса для квантированного ResNet20 в int8 
├── src
│   ├── model.py        ### Файл с имплементацией ResNet блока и архитектуры               
│   ├── qmodel.py       ### Файл с имплементацией квантированных аналогов блоков из PyTorch        
│   ├── train.py        ### Функции для тренировки и валидации нейронной сети  
│   ├── utils.py        ### Всякие полезные функции
│   └── __init__.py
├── PTQ.ipynb           ### Короткий нотбук с реализацией квантированной ResNet20 в int2, int4, int8. В int8 с совмещением Conv2d и Batch Norm.
│                       ### Так же тестирование моей имплементации квантизирования и основные результаты
├── train_resnet.py     ### Файл с тренировкой ResNet20
├── requirements.txt
└── README.md
```



Реализованно
[Vladimir Kondratyev](https://github.com/VldKnd)

---
**Шаг 1.** Ознакомиться с понятием Quantization.  

На данном шаге предлагается разобраться с понятием Quantization и со стандартными техниками, как dynamic, static, post training и quantization aware quantization.

**Шаг 2.** Скачать датасет CIFAR10.

**Шаг 3.** Реализовать архитектуру ResNet20.

**Шаг 4.** Обучить ResNet20.  

**Шаг 5.** Применить готовые решения для post training quantization (далее PTQ).  

> Квантовать к 16 и 8 битам. Квантовать уже обученную модель, которая была получена на шаге 4.

**Шаг 6.** Реализовать PTQ.

> Квантовать к 16, 8, 4 и 2 битам. Квантовать уже обученную модель, которая была получена на шаге 4.

**Шаг 7.** Сравнение результатов

---
